training:
  eval_interval: 1000
  log_interval: 200
  eval_iters: 200
  eval_only: false
  always_save_checkpoint: true
  init_from: "scratch"
  gradient_accumulation_steps: 1
  batch_size: 512
  max_iters: 100000
  time_limit_seconds: 86400
  max_iters_per_launch: 10000
  early_stopping_patience: 10
  save_numbered_checkpoints: false
  consistency_weight: 0.1
  smoothness_weight: 0.1

optimizer:
  learning_rate: 0.001
  min_lr: 1e-5
  warmup_iters: 500
  lr_decay_iters: 1000
  decay_lr: true
  weight_decay: 0.1
  beta1: 0.9
  beta2: 0.95
  grad_clip: 1.0
  scheduler:
    type: "cosine"
    factor: 0.1
    patience: 5

model:
  image_size: 32
  n_layer: 2
  n_head: 2
  n_embd: 64
  use_nvit: true
  num_classes: 100
  dropout: 0.15
  bias: true
  flash_attn: true
  sz_init_value: 1.00
  sz_init_scaling: 1.0
  local_patch_size: 8
  global_patch_size: 16
  kohonen_nodes: 64
  kohonen_alpha: 0.02
  use_kohonen: true
  reconstruction_weight: 0.5
  map_balance_weight: 0.25
  local_quantization_weight: 0.125
  global_quantization_weight: 0.125
  kohonen_scheduler:
    enabled: true
    warmup_steps: 1000
    decay_steps: 10000
    min_lr: 0.001

system:
  device: "cuda"
  dtype: "bfloat16"
  use_ddp: true
  compile: true
  backend: "nccl"
  log_level: "INFO"
  log_to_file: true
  memory_threshold: 0.9
  log_memory: true
  log_gpu_stats: true
  clear_cache: true
  quick_validation: true
  quick_validation_size: 1000
  use_amp: true
  use_tqdm: true

wandb:
  mode: "online"
  project: "phd"
  run_name: "nvit_"
  save_artifacts: true
  artifact_description: "ViT model checkpoint"
  artifact_name: "nvit_cifar100"

data:
  out_dir: "./out"
  dataset: "cifar100"
  checkpoint_dir: "./out"
  checkpoint_file: 'checkpoint_latest.pt'
  num_workers: 4
  augmentation:
    enabled: true
    color_jitter: 0.2
    random_affine: true
    cutout: false
    auto_augment: true