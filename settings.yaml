training:
  eval_interval: 1000
  log_interval: 200
  eval_iters: 200
  eval_only: false
  always_save_checkpoint: true
  init_from: "scratch"
  gradient_accumulation_steps: 16
  batch_size: 8
  max_iters: 100000
  time_limit_seconds: 86400
  max_iters_per_launch: 100000
  early_stopping_patience: 10
  save_numbered_checkpoints: false

optimizer:
  learning_rate: 0.0005
  min_lr: 1e-5
  warmup_iters: 1000
  lr_decay_iters: 10000
  decay_lr: true
  weight_decay: 0.1
  beta1: 0.9
  beta2: 0.95
  grad_clip: 1.0
  scheduler:
    type: "cosine"
    factor: 0.1
    patience: 5

model:
  image_size: 32
  patch_size: 4
  n_layer: 3
  n_head: 4
  n_embd: 128
  use_nViT: 1
  num_classes: 10
  dropout: 0.05
  bias: true
  sz_init_value: 1.00
  sz_init_scaling: 1.0

system:
  device: "cuda"
  dtype: "bfloat16"
  use_ddp: true
  compile: true
  backend: "nccl"
  log_level: "INFO"
  log_to_file: true
  memory_threshold: 0.9
  log_memory: true
  log_gpu_stats: true
  clear_cache: true
  quick_validation: true
  quick_validation_size: 1000
  use_amp: true
  use_tqdm: true

wandb:
  mode: "online"
  project: "phd"
  run_name: "nvit_"
  save_artifacts: true
  artifact_description: "ViT model checkpoint"
  artifact_name: "nvit_cifar10"

data:
  out_dir: "./out"
  dataset: "cifar10"
  checkpoint_dir: "./out"
  checkpoint_file: 'checkpoint_latest.pt'
  num_workers: 4
  augmentation:
    enabled: true
    color_jitter: 0.2
    random_affine: true
    cutout: false
    auto_augment: true